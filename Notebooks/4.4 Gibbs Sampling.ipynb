{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/cartel.jpg\">\n",
    "<!--COURSE_INFORMATION-->\n",
    "## This notebook contains the index from the course [Biology Meets Programming](https://www.coursera.org/learn/bioinformatics/home/welcome) by University of California in Coursera \n",
    "\n",
    "\n",
    "### The content is available [on GitHub](https://github.com/vencejo/Curso_BiologyMeetsProgramming)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [4.3 How Can a Randomized Algorithm Perform So Well? ](4.3 How Can a Randomized Algorithm Perform So Well%3F.ipynb)| [Contents](Index.ipynb) |  [4.5 Detour Buffon's Needle ](4.5 Detour Buffon's Needle.ipynb) >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig71.png\">\n",
    "\n",
    "Like RandomizedMotifSearch, GibbsSampler starts with randomly chosen k-mers in each of t DNA strings, but it makes a random choice at each iteration. It uses a list of t randomly selected k-mers Motifs to come up with another (hopefully better scoring) set of k-mers. In contrast with RandomizedMotifSearch, which defines new motifs as \n",
    "\n",
    "    Motifs(Profile(Motifs), Dna)\n",
    "\n",
    "GibbsSampler randomly selects an integer i between 0 and t-1 and then randomly changes a single k-mer Motif[i]. That is, GibbsSampler makes two random choices at each iteration. It uses random.randint(0, t-1) for the first choice (since all t strings in Dna are equally likely), but it does not make sense to use random.randint to choose a k-mer from Motif[i] because some k-mers are more likely than others. Indeed, each k-mer Pattern in Motif[i] may have a different probability Pr(Pattern, Profile) that it was generated by Profile\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig72.png\">\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig73.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rescale a collection of probabilities (the sides of the die) so that these probabilities sum to 1, we will write a function called Normalize(Probabilities). This function takes a dictionary Probabilities whose keys are k-mers and whose values are the probabilities of these k-mers (which do not necessarily sum to 1). The function should divide each value in Probabilities by the sum of all values in  Probabilities, then return the resulting dictionary.\n",
    "\n",
    "```python\n",
    "# Input: A dictionary Probabilities, where keys are k-mers and values are the probabilities of these k-mers (which do not necessarily sum up to 1)\n",
    "# Output: A normalized dictionary where the probability of each k-mer was divided by the sum of all k-mers' probabilities\n",
    "def Normalize(Probabilities):\n",
    "    P = 0\n",
    "    for key in Probabilities:\n",
    "        P += Probabilities[key]\n",
    "    for key in Probabilities:\n",
    "        Probabilities[key] = Probabilities[key] / P \n",
    "    return Probabilities\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "We now need to simulate rolling a die so that \"ccgG\" has probability 4/80, \"cgGC\" has probability 8/80, and so on. We will do so by generating a random number p between 0 and 1. If p is between 0 and 4/80, then it corresponds to \"ccgG\". If p is between 4/80 and 4/80 + 8/80, then it corresponds to \"cgGC\", etc.\n",
    "\n",
    "How can we generate a random number between 0 and 1? In addition to the randint function, Python’s random module also includes a function called uniform(a, b) that generates a random floating point number (i.e., a decimal) between a and b. We can therefore generate our desired random number p by calling random.uniform(0, 1).\n",
    "\n",
    "Code Challenge (3 points): Generalize this idea by writing a function WeightedDie(Probabilities). This function takes a dictionary Probabilities whose keys are k-mers and whose values are the probabilities of these k-mers. The function should return a randomly chosen k-mer key with respect to the values in Probabilities. Then add this function to Motifs.py.\n",
    "\n",
    "(Note: the 1 at the beginning of the sample dataset is simply for grading purposes, so please ignore it.)\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "1\n",
    "0.25 A\n",
    "0.25 C\n",
    "0.25 G\n",
    "0.25 T\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "T\n",
    "\n",
    "```python\n",
    "# Input:  A dictionary Probabilities whose keys are k-mers and whose values are the probabilities of these kmers\n",
    "# Output: A randomly chosen k-mer with respect to the values in Probabilities\n",
    "def WeightedDie(Probabilities):\n",
    "\n",
    "    lineaProb = {}\n",
    "    probAcumulada = 0\n",
    "    for key in Probabilities.keys():\n",
    "        lineaProb[key] = probAcumulada + Probabilities[key]\n",
    "        probAcumulada = probAcumulada + Probabilities[key]\n",
    "        \n",
    "    p = random.uniform(0, 1)\n",
    "\n",
    "    lineaProbOrd = sorted(lineaProb.items(), key = lambda x: x[1])\n",
    "\n",
    "    for tupla in lineaProbOrd:\n",
    "        if p <= tupla[1]:\n",
    "            return tupla[0]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now that we can simulate a weighted die roll over a collection of probabilities of strings, we need to make this function into a subroutine of a larger function that randomly chooses a k-mer from a string Text based on a profile matrix profile.\n",
    "\n",
    "In other words, after setting the length of text and declaring a blank dictionary,\n",
    "\n",
    "    n = len(Text)\n",
    "    probabilities = {} \n",
    "\n",
    "we range over all possible k-mers in Text, computing the probability of each one and placing this probability into a dictionary.\n",
    "\n",
    "    for i in range(0,n-k+1):\n",
    "        probabilities[Text[i:i+k]] = Pr(Text[i:i+k], profile)\n",
    "\n",
    "We then normalize these probabilities using the Normalize(probabilities) subroutine, and then return the result of rolling a weighted die over this dictionary to produce a k-mer.\n",
    "\n",
    "    probabilities = Normalize(probabilities)\n",
    "    return WeightedDie(probabilities)\n",
    "\n",
    "Code Challenge (3 points): Assemble this code into a function ProfileGeneratedString(Text, profile, k) that takes a string Text, a profile matrix profile , and an integer k as input.  It should then return a randomly generated k-mer from Text whose probabilities are generated from profile, as described above.  Then add this function to Motifs.py.\n",
    "\n",
    "Note that the 1 at the beginning of the sample dataset is simply for grading purposes (so ignore it).\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "1\n",
    "AAACCCAAACCC\n",
    "{'A': [0.5, 0.1], 'C': [0.3, 0.2], 'G': [0.2, 0.4], 'T': [0.0, 0.3]}\n",
    "2\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "AC\n",
    "\n",
    "```python\n",
    "# Input:  A string Text, a profile matrix Profile, and an integer k\n",
    "# Output: ProfileGeneratedString(Text, profile, k)\n",
    "def ProfileGeneratedString(Text, profile, k):\n",
    "    n = len(Text)\n",
    "    probabilities = {}\n",
    "    for i in range(0,n-k+1):\n",
    "        probabilities[Text[i:i+k]] = Pr(Text[i:i+k], profile)\n",
    "        \n",
    "    probabilities = Normalize(probabilities)\n",
    "    return WeightedDie(probabilities)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig74.png\">\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig75.png\">\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig76.png\">\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig77.png\">\n",
    "\n",
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig78.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Challenge (3 points): Now that you have seen how GibbsSampler works, implement it in Python as a final challenge in this chapter. Your function should take a parameter N corresponding to the number of iterations that we plan to run the program. Don't forget to use pseudocounts!\n",
    "\n",
    "Note: If you have trouble implementing GibbsSampler, please see below, where we provide a description of GibbsSampler using pseudocode, a method of describing algorithms that is not dependent on a particular programming language like Python. If you are interested in learning more about how biological problems can be solved computationally, please check out our Bioinformatics Specialization or its print companion, Bioinformatics Algorithms: An Active Learning Approach, which uses pseudocode to discuss dozens of bioinformatics algorithms.\n",
    "\n",
    "    GibbsSampler(Dna, k, t, N)\n",
    "        randomly select k-mers Motifs = (Motif1, …, Motift) in each string from Dna\n",
    "        ﻿BestMotifs ← Motifs\n",
    "        for j ← 1 to N\n",
    "            i ← randomly generated integer between 1 and t\n",
    "            Profile ← profile matrix formed from all strings in Motifs except for Motifi\n",
    "            Motifi ← Profile-randomly generated k-mer in the i-th string\n",
    "            if Score(Motifs) < Score(BestMotifs)\n",
    "                BestMotifs ← Motifs\n",
    "        return BestMotifs\n",
    "        \n",
    "Sample Input:\n",
    "\n",
    "8 5 100\n",
    "CGCCCCTCTCGGGGGTGTTCAGTAAACGGCCA\n",
    "GGGCGAGGTATGTGTAAGTGCCAAGGTGCCAG\n",
    "TAGTACCGAGACCGAAAGAAGTATACAGGCGT\n",
    "TAGATCAAGTTTCAGGTGCACGTCGGTGAACC\n",
    "AATCCACCAGCTCCACGTGCAATGTTGGCCTA\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "AACGGCCA\n",
    "AAGTGCCA\n",
    "TAGTACCG\n",
    "AAGTTTCA\n",
    "ACGTGCAA\n",
    "\n",
    "```python\n",
    "# Input:  Integers k, t, and N, followed by a collection of strings Dna\n",
    "# Output: GibbsSampler(Dna, k, t, N)\n",
    "def GibbsSampler(Dna, k , t, N):\n",
    "    M = RandomMotifs(Dna, k, t)\n",
    "    BestMotifs = M\n",
    "    for j in range(N):\n",
    "        i = random.randint(0,t-1)\n",
    "        M.pop(i)\n",
    "        Profile =  ProfileWithPseudocounts(M)\n",
    "        newMotif =  ProfileGeneratedString(Dna[i], Profile, k)\n",
    "        M.insert(i,newMotif)\n",
    "        if Score(M) < Score(BestMotifs):\n",
    "            BestMotifs = M\n",
    "        \n",
    "    return BestMotifs\n",
    "```\n",
    "\n",
    "Exercise Break (1 point): Run GibbsSampler on the DosR dataset (click here to download) for 20 different starts, each time with N = 100, and with k-mer length equal to 15. Don't forget to use pseudocounts!\n",
    "\n",
    "Passed test #2. Correct! Below is the best set of Motifs in the DosR with k = 15 using GibbsSampler (with a score of 38):\n",
    "GACGAATGACCCCAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"padding-right:10px;\" src=\"figures/fig79.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motif of length 20 found by RandomizedMotifSearch is \"CGGGACCTACGTCCCTAGCC\" (with score 57). In 2000 runs, GibbsSampler generated a different collection of motifs with a smaller score of 55. But these motifs had the same consensus string!\n",
    "\n",
    "Despite evidence in favor of this consensus string as the DosR motif, we are still not sure that it should have length 20, or even that it is correct, since some other motif finding algorithm might find a set of motifs with even lower score. Can you further refine the algorithms that we have presented to find all putative DosR motifs in MTB as well as all genes that they regulate?\n",
    "\n",
    "We hope that you have enjoyed learning a little more about how computation is vital to modern biology, and that we have helped you start a path toward becoming an expert programmer. We would love to have you in the Bioinformatics Specialization, an entire series of courses at the frontier of computational biology; if you're interested, please see the Specialization's wacky introductory video at the bottom of the page :)\n",
    "\n",
    "Even more importantly, you don't have to program in order to complete the [Bioinformatics Specialization](https://www.coursera.org/specializations/bioinformatics). We employ pseudocode, a powerful paradigm that helps us discuss algorithms without relying on any particular programming language. If you are interested in continuing on with implementing algorithms, then we provide an \"Honors Track\" in which you can flex your programming muscles. The first course in the series, Finding Hidden Messages in DNA, covers much of the same introductory material that we have seen in this class, in the hope of making your transition to the Bioinformatics Specialization as easy as possible. \n",
    "\n",
    "And if you plan on still using Python, you should be ready to complete the remainder of the Codecademy Python Track. In addition, you now have two files (Replication.py and Motifs.py) full of functions to get you started with running Python on your own machine. To do so, download the latest version of Python 3 from the Python website. We also suggest downloading a development environment like PyCharm that will make building your own projects in Python a breeze.\n",
    "\n",
    "Happy Coding!\n",
    "\n",
    "Phillip & Pavel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [4.3 How Can a Randomized Algorithm Perform So Well? ](4.3 How Can a Randomized Algorithm Perform So Well%3F.ipynb)| [Contents](Index.ipynb) |  [4.5 Detour Buffon's Needle ](4.5 Detour Buffon's Needle.ipynb) >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
